{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWT0bopBIPfa"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/rcpaffenroth/dac_raghu/blob/main/LunarLander.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2iIpCtRVnAT"
      },
      "source": [
        "# Setup and libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Colab specific stuff\n",
        "\n",
        "This is some code to make sure that the notebook works in Colab. It's not used when you are running things locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i7rbbIzgUsoH"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruJt504TJgdh",
        "outputId": "ab6a4eb8-dffd-4e92-8b1d-31fd78cacf1f"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  ! apt-get install swig\n",
        "  ! pip install stable-baselines3[extra] gymnasium[box2d] huggingface_sb3\n",
        "else:\n",
        "  # Otherwise, install locally and you need the following\n",
        "  # NOTE: Need \"gym\" and \"gymnasium\" installed, since we use \"gymnasium\" for the LunarLander environment\n",
        "  #       and \"gym\" is for huggingface_sb3.\n",
        "  # sudo apt install swig ffmpeg\n",
        "  # pip install stable-baselines3[extra] gymnasium[box2d] huggingface_sb3 imageio[ffmpeg] gym ipywidegets ipykernel pandas pyarrow\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the needed libraries\n",
        "\n",
        "These are the libraries I will be using for this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObPgW5p7IJCW",
        "outputId": "f98150cb-fdbe-4107-d71a-cf0647206059"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import imageio\n",
        "from stable_baselines3 import PPO\n",
        "from huggingface_sb3 import load_from_hub\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import HTML\n",
        "from ipywidgets import interact, widgets\n",
        "from base64 import b64encode\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The Lander environment.  \n",
        "\n",
        "It is trying to land softly between the two flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f3qMKvCMIJCY"
      },
      "outputs": [],
      "source": [
        "# Make the environment\n",
        "env = gym.make(\"LunarLander-v2\", render_mode='rgb_array')\n",
        "observation = env.reset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is the top level link to the library\n",
        "\n",
        "https://gymnasium.farama.org/\n",
        "\n",
        "Here is the Lunar Lander specific link\n",
        "\n",
        "https://gymnasium.farama.org/environments/box2d/lunar_lander/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Action Space\n",
        "There are four discrete actions available:\n",
        "\n",
        "0: do nothing\n",
        "\n",
        "1: fire left orientation engine\n",
        "\n",
        "2: fire main engine\n",
        "\n",
        "3: fire right orientation engine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Observation Space\n",
        "\n",
        "The state is an 8-dimensional vector: the coordinates of the lander in x & y, its linear velocities in x & y, its angle, its angular velocity, and two booleans that represent whether each leg is in contact with the ground or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "obs_names = ['x', 'y', 'vx', 'vy', 'theta', 'vtheta', 'leg1', 'leg2']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rewards\n",
        "\n",
        "After every step a reward is granted. The total reward of an episode is the sum of the rewards for all the steps within that episode.\n",
        "\n",
        "For each step, the reward:\n",
        "\n",
        "is increased/decreased the closer/further the lander is to the landing pad.\n",
        "\n",
        "is increased/decreased the slower/faster the lander is moving.\n",
        "\n",
        "is decreased the more the lander is tilted (angle not horizontal).\n",
        "\n",
        "is increased by 10 points for each leg that is in contact with the ground.\n",
        "\n",
        "is decreased by 0.03 points each frame a side engine is firing.\n",
        "\n",
        "is decreased by 0.3 points each frame the main engine is firing.\n",
        "\n",
        "The episode receive an additional reward of -100 or +100 points for crashing or landing safely respectively.\n",
        "\n",
        "An episode is considered a solution if it scores at least 200 points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Starting State\n",
        "\n",
        "The lander starts at the top center of the viewport with a random initial force applied to its center of mass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Episode Termination\n",
        "\n",
        "The episode finishes if:\n",
        "\n",
        "the lander crashes (the lander body gets in contact with the moon);\n",
        "\n",
        "the lander gets outside of the viewport (x coordinate is greater than 1);\n",
        "\n",
        "the lander is not awake. From the Box2D docs, a body which is not awake is a body which doesn’t move and doesn’t collide with any other body:\n",
        "\n",
        "When Box2D determines that a body (or group of bodies) has come to rest, the body enters a sleep state which has very little CPU overhead. If a body is awake and collides with a sleeping body, then the sleeping body wakes up. Bodies will also wake up if a joint or contact attached to them is destroyed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9xZJaSBVYGZ"
      },
      "source": [
        "# Training and downloading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gYpJvvJ1YwBs"
      },
      "outputs": [],
      "source": [
        "class RandomModel(object):\n",
        "  def __init__(self, env):\n",
        "    self.env = env\n",
        "\n",
        "  def predict(self, obs):\n",
        "    return env.action_space.sample(), None # The second return value is the state value, which the random model does not use\n",
        "\n",
        "random_model =  RandomModel(env)\n",
        "models['random'] = {}\n",
        "models['random']['model'] = random_model\n",
        "models['random']['runs'] = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_LcXjSjIJCa",
        "outputId": "d86fc160-2ed6-4efa-befd-a2b2edb82da6"
      },
      "outputs": [],
      "source": [
        "# This is an trained model that has a good architecture and loss function, but is not trained very much.  This takes about 30 sec on \n",
        "# a RTX 4090\n",
        "trained_model = PPO(\"MlpPolicy\", env)\n",
        "trained_model.learn(total_timesteps=20000)\n",
        "\n",
        "models['trained'] = {}\n",
        "models['trained']['model'] = trained_model\n",
        "models['trained']['runs'] = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK-mnlzyWXmb",
        "outputId": "e6dde32e-374c-47df-e299-60ed1093c16a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rcpaffenroth/projects/dac_raghu/venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: an integer is required (got type bytes)\n",
            "  warnings.warn(\n",
            "/home/rcpaffenroth/projects/dac_raghu/venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: an integer is required (got type bytes)\n",
            "  warnings.warn(\n",
            "/home/rcpaffenroth/projects/dac_raghu/venv/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# This is a model from huggingface.co at https://huggingface.co/sb3/a2c-LunarLander-v2\n",
        "# Mean reward: 181.08 +/- 95.35\n",
        "checkpoint = load_from_hub(\n",
        "    repo_id=\"sb3/a2c-LunarLander-v2\",\n",
        "    filename=\"a2c-LunarLander-v2.zip\",\n",
        ")\n",
        "\n",
        "good_model = PPO.load(checkpoint)\n",
        "\n",
        "models['good'] = {}\n",
        "models['good']['model'] = good_model\n",
        "models['good']['runs'] = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rcpaffenroth/projects/dac_raghu/venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: an integer is required (got type bytes)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# This is a model from huggingface.co at https://huggingface.co/araffin/ppo-LunarLander-v2\n",
        "# Mean reward:  283.49 +/- 13.74\n",
        "checkpoint = load_from_hub(\n",
        "    repo_id=\"araffin/ppo-LunarLander-v2\",\n",
        "    filename=\"ppo-LunarLander-v2.zip\",\n",
        ")\n",
        "\n",
        "better_model = PPO.load(checkpoint)\n",
        "models['better'] = {}\n",
        "models['better']['model'] = better_model\n",
        "models['better']['runs'] = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq_dUEp9YkcA"
      },
      "source": [
        "# Evaluate models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOBZwfCqIJCc"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model_name, models=models, env=env):\n",
        "   # Make a movie of a trained agent\n",
        "   obs = env.reset()[0]\n",
        "\n",
        "   # Get the model\n",
        "   model = models[model_name]['model']\n",
        "   images = []\n",
        "   all_obs = []\n",
        "   all_actions = []\n",
        "   all_rewards = []\n",
        "   done = False\n",
        "   while not done:\n",
        "      # This rendering mode puts an image into a numpy array\n",
        "      images += [env.render()]\n",
        "      action, _state = model.predict(obs)\n",
        "      all_obs.append(obs)\n",
        "      all_actions.append(int(action))\n",
        "      obs, reward, done, trunc, info = env.step(action)\n",
        "      all_rewards.append(reward)\n",
        "   env.close()\n",
        "\n",
        "   df = pd.DataFrame(all_obs, columns=obs_names)\n",
        "   df['action'] = all_actions\n",
        "   df['reward'] = all_rewards\n",
        "   models[model_name]['runs'].append({'data':df,'images':images})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    evaluate_model('random')\n",
        "    evaluate_model('trained')\n",
        "    evaluate_model('good')\n",
        "    evaluate_model('better')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "rx-9iDZhIJCg",
        "outputId": "dc4b109d-b664-4c03-878d-73df4c5c19f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99a7c59628a04f4ba2de3a117e7b35ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='model_name', options=('random', 'trained', 'good', 'better'), valu…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "@interact(model_name=models.keys(), run_idx=widgets.IntSlider(min=0, max=9, step=1, value=0))\n",
        "def show_video(model_name, run_idx):\n",
        "      images = models[model_name]['runs'][run_idx]['images']      \n",
        "      # imageio is a nice library for taking a sequence of images and makeing a movie\n",
        "      name = 'tmp.mp4'\n",
        "      imageio.mimsave(name, images, fps=15)\n",
        "      mp4 = open(name,'rb').read()\n",
        "      data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "      # This puts the video in the notebook\n",
        "      display(HTML(\"\"\"\n",
        "      <video width=400 controls>\n",
        "            <source src=\"%s\" type=\"video/mp4\">\n",
        "      </video>\n",
        "      \"\"\" % data_url))\n",
        "      # plot various data for the run \n",
        "      _, ax = plt.subplots(1, 3)\n",
        "      data = models[model_name]['runs'][run_idx]['data']\n",
        "      ax[0].plot(data['reward'])\n",
        "      ax[0].set_title('reward')\n",
        "      ax[1].plot(data['x'], data['y'])\n",
        "      ax[1].set_title('position')\n",
        "      ax[2].plot(data['vx'], data['vy'])\n",
        "      ax[2].set_title('velocity')\n",
        "      plt.tight_layout()\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random: -93.99\n",
            "random: -81.28\n",
            "random: -413.56\n",
            "random: -290.40\n",
            "random: -208.04\n",
            "random: -144.48\n",
            "trained: -97.65\n",
            "trained: -46.18\n",
            "trained: -92.97\n",
            "trained: -137.37\n",
            "trained: -79.68\n",
            "trained: -125.16\n",
            "good: 19.11\n",
            "good: 42.30\n",
            "good: 91.65\n",
            "good: 0.48\n",
            "good: 90.99\n",
            "good: 215.07\n",
            "better: 286.70\n",
            "better: 276.52\n",
            "better: 320.30\n",
            "better: 281.09\n",
            "better: 271.67\n",
            "better: 259.02\n"
          ]
        }
      ],
      "source": [
        "for model_name in models.keys():\n",
        "    for run_idx in range(len(models[model_name]['runs'])):\n",
        "        data = models[model_name]['runs'][run_idx]['data']  \n",
        "        # Print the total reward for each model\n",
        "        print(f\"{model_name}: {np.sum(data['reward']):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save model trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ArrowInvalid",
          "evalue": "('Can only convert 1-dimensional array values', 'Conversion failed for column action with type object')",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m run_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(models[model_name][\u001b[39m'\u001b[39m\u001b[39mruns\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[1;32m      3\u001b[0m     data \u001b[39m=\u001b[39m models[model_name][\u001b[39m'\u001b[39m\u001b[39mruns\u001b[39m\u001b[39m'\u001b[39m][run_idx][\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]  \n\u001b[0;32m----> 4\u001b[0m     data\u001b[39m.\u001b[39;49mto_parquet(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_name\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mrun_idx\u001b[39m}\u001b[39;49;00m\u001b[39m_trajectory.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pandas/core/frame.py:2889\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[39mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[39m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 2889\u001b[0m \u001b[39mreturn\u001b[39;00m to_parquet(\n\u001b[1;32m   2890\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2891\u001b[0m     path,\n\u001b[1;32m   2892\u001b[0m     engine,\n\u001b[1;32m   2893\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   2894\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2895\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m   2896\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2897\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2898\u001b[0m )\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pandas/io/parquet.py:411\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m    409\u001b[0m path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO() \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m--> 411\u001b[0m impl\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m    412\u001b[0m     df,\n\u001b[1;32m    413\u001b[0m     path_or_buf,\n\u001b[1;32m    414\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    415\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    416\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m    417\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    418\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    419\u001b[0m )\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    422\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, io\u001b[39m.\u001b[39mBytesIO)\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pandas/io/parquet.py:159\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     from_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39mpreserve_index\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m index\n\u001b[0;32m--> 159\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mTable\u001b[39m.\u001b[39;49mfrom_pandas(df, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfrom_pandas_kwargs)\n\u001b[1;32m    161\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    162\u001b[0m     path,\n\u001b[1;32m    163\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     is_dir\u001b[39m=\u001b[39mpartition_cols \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    169\u001b[0m     \u001b[39misinstance\u001b[39m(path_or_handle, io\u001b[39m.\u001b[39mBufferedWriter)\n\u001b[1;32m    170\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(path_or_handle, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    171\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_handle\u001b[39m.\u001b[39mname, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m))\n\u001b[1;32m    172\u001b[0m ):\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pyarrow/table.pxi:3681\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    607\u001b[0m             arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m\n\u001b[1;32m    608\u001b[0m             \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[1;32m    612\u001b[0m               \u001b[39mfor\u001b[39;00m c, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     arrays \u001b[39m=\u001b[39m []\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    607\u001b[0m             arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m\n\u001b[1;32m    608\u001b[0m             \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[1;32m    612\u001b[0m               \u001b[39mfor\u001b[39;00m c, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     arrays \u001b[39m=\u001b[39m []\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m field_nullable \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mnull_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mField \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m was non-nullable but pandas column \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mhad \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m null values\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[39m.\u001b[39mnull_count))\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[39m=\u001b[39m field\u001b[39m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(col, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49mtype_, from_pandas\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, safe\u001b[39m=\u001b[39;49msafe)\n\u001b[1;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pyarrow/array.pxi:323\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pyarrow/array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/projects/dac_raghu/venv/lib/python3.8/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mArrowInvalid\u001b[0m: ('Can only convert 1-dimensional array values', 'Conversion failed for column action with type object')"
          ]
        }
      ],
      "source": [
        "for model_name in models.keys():\n",
        "    for run_idx in range(len(models[model_name]['runs'])):\n",
        "        data = models[model_name]['runs'][run_idx]['data']  \n",
        "        data.to_parquet(f'data/{model_name}_{run_idx}_trajectory.parquet')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      3\n",
              "1      0\n",
              "2      2\n",
              "3      3\n",
              "4      0\n",
              "      ..\n",
              "175    2\n",
              "176    2\n",
              "177    1\n",
              "178    3\n",
              "179    1\n",
              "Name: action, Length: 180, dtype: object"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['action']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Write files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This section produces the data for a generative model of the Lunar Lander\n",
        "# Create a single dataframe with all the data\n",
        "# each row is a single run of a single model\n",
        "# each column is a single timestep of a single variable\n",
        "\n",
        "# NOTE:  There needs to be some thinking here.  I mean, while the position,\n",
        "# velocity, and angle are all continuous, the thrust is not.  So, we need to\n",
        "# thinkg about how to interpolate the thrust. I think the data in this case\n",
        "# needs to be \"ragged\" in the sense that each row has a different number of\n",
        "# entries.  However, perhaps we can also just look at the \"shortest\" run and\n",
        "# truncate all the other runs to that length. \n",
        "\n",
        "\n",
        "# TODO:  This is getting close, but is not there yet.  I want things like\n",
        "# 'x,x,x' to be something like 'x1,x2,x3' so that I can use the autoencoder\n",
        "# more easily.  Is that a matter of combining the columns?  I think so.  \n",
        "# How about keeping a dict to map times to indices?  That would work I think.\n",
        "\n",
        "def uniform_data_for_autoencoder(filename, entries_per_run=100):\n",
        "    all_data = []\n",
        "    for model_name in models.keys():\n",
        "        for run_idx in range(len(models[model_name]['runs'])):\n",
        "            df = models[model_name]['runs'][run_idx]['data'].copy()  \n",
        "\n",
        "            # index plays the role of timestep\n",
        "            df['timestamp'] = pd.to_datetime(df.index, unit='s')\n",
        "            df.set_index('timestamp', inplace=True)\n",
        "\n",
        "            # We now compute the delta t that gives us 100 total sample points for each run\n",
        "            # We do this by taking the total time of the run and dividing by 100\n",
        "            total_time = df.index[-1] - df.index[0]\n",
        "            delta_t = total_time / entries_per_run\n",
        "            df = df.resample(delta_t).interpolate()\n",
        "\n",
        "            df = pd.melt(df, \n",
        "                        value_vars=['x', 'y', 'vx', 'vy', 'theta', 'vtheta'], \n",
        "                        var_name='variable', \n",
        "                        ignore_index=False, \n",
        "                        value_name='value')\n",
        "            # How to add a few additional rows to the dataframe\n",
        "            df.loc[df.index[0]] = ['model_name', model_name]\n",
        "            df.loc[df.index[-1]] = ['total_time', total_time]\n",
        "            all_data.append(df)\n",
        "\n",
        "    # for i,df in enumerate(all_data):\n",
        "    #     if i == 0:\n",
        "    #         all_data = pd.DataFrame(df).T\n",
        "    #     df['run_idx'] = i    \n",
        "    # all_data = pd.concat(all_data)\n",
        "    # all_data.to_parquet(filename)\n",
        "    return all_data\n",
        "all_data = uniform_data_for_autoencoder('data/uniform_data_for_autoencoder.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tmp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mvariable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m tmp\u001b[39m.\u001b[39mloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m tmp\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "tmp = pd.DataFrame(columns=df['variable'])\n",
        "tmp.loc[-1] = list(df['value'])\n",
        "tmp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "timestamp\n",
              "1970-01-01 00:00:00.000             better\n",
              "1970-01-01 00:00:02.360          -0.016149\n",
              "1970-01-01 00:00:04.720          -0.025983\n",
              "1970-01-01 00:00:07.080          -0.035816\n",
              "1970-01-01 00:00:09.440          -0.045649\n",
              "                                ...       \n",
              "1970-01-01 00:03:46.560           0.006841\n",
              "1970-01-01 00:03:48.920            0.00513\n",
              "1970-01-01 00:03:51.280            0.00342\n",
              "1970-01-01 00:03:53.640            0.00171\n",
              "1970-01-01 00:03:56.000    0 days 00:03:56\n",
              "Name: value, Length: 606, dtype: object"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "91c69d281b806a3add6b161e23d9089dcb392788fdbe6cdd17c006940cab5b65"
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
